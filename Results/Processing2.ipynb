{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from IndianConstitution_incremental_results.csv...\n",
      "Initial number of rows: 487\n",
      "Number of rows removed: 38\n",
      "Number of rows remaining: 449\n",
      "Loading sentence transformer model...\n",
      "Computing embedding similarities...\n",
      "Filtered data saved to IndianConstitution_filtered_results.csv\n",
      "\n",
      "Summary:\n",
      "Number of questions left: 449\n",
      "Number of questions removed: 38\n",
      "Average BLEU: 0.2065\n",
      "Average ROUGE-1: 0.3632\n",
      "Average ROUGE-2: 0.2839\n",
      "Average ROUGE-L: 0.3466\n",
      "Average Embedding Similarity: 0.8450\n",
      "Average MiniLM Embedding Similarity: 0.5389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34045/3206300517.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['mini_lm_similarity'] = embedding_similarities\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def process_csv(input_file='IndianConstitution_incremental_results.csv'):\n",
    "    # Load the CSV file\n",
    "    print(f\"Loading data from {input_file}...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Count the initial number of rows\n",
    "    initial_row_count = len(df)\n",
    "    print(f\"Initial number of rows: {initial_row_count}\")\n",
    "    \n",
    "    # Define patterns to search for in generated answers\n",
    "    patterns = [\n",
    "        r'i am sorry', \n",
    "        r'i cannot', \n",
    "        r'I am unable', \n",
    "        r'Agent stopped'\n",
    "    ]\n",
    "    \n",
    "    # Create a regex pattern with case insensitivity\n",
    "    combined_pattern = '|'.join(patterns)\n",
    "    \n",
    "    # Filter out rows containing the patterns\n",
    "    mask = df['generated_answer'].str.lower().str.contains(combined_pattern, regex=True)\n",
    "    df_filtered = df[~mask]\n",
    "    \n",
    "    # Count the number of rows removed\n",
    "    removed_rows = initial_row_count - len(df_filtered)\n",
    "    print(f\"Number of rows removed: {removed_rows}\")\n",
    "    print(f\"Number of rows remaining: {len(df_filtered)}\")\n",
    "    \n",
    "    # Load sentence transformer model\n",
    "    print(\"Loading sentence transformer model...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "    \n",
    "    # Compute embedding similarity\n",
    "    print(\"Computing embedding similarities...\")\n",
    "    embedding_similarities = []\n",
    "    \n",
    "    # Process in batches to avoid potential memory issues\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(df_filtered), batch_size):\n",
    "        batch = df_filtered.iloc[i:i+batch_size]\n",
    "        generated_embeddings = model.encode(batch['generated_answer'].tolist())\n",
    "        gold_embeddings = model.encode(batch['gold_answer'].tolist())\n",
    "        \n",
    "        for j in range(len(batch)):\n",
    "            gen_emb = generated_embeddings[j].reshape(1, -1)\n",
    "            gold_emb = gold_embeddings[j].reshape(1, -1)\n",
    "            similarity = cosine_similarity(gen_emb, gold_emb)[0][0]\n",
    "            embedding_similarities.append(similarity)\n",
    "    \n",
    "    # Add new column for embedding similarity\n",
    "    df_filtered['mini_lm_similarity'] = embedding_similarities\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_bleu = df_filtered['bleu'].mean()\n",
    "    avg_rouge1 = df_filtered['rouge-1'].mean()\n",
    "    avg_rouge2 = df_filtered['rouge-2'].mean()\n",
    "    avg_rougel = df_filtered['rouge-l'].mean()\n",
    "    avg_embedding_sim = df_filtered['embedding_similarity'].mean()\n",
    "    avg_mini_lm_sim = df_filtered['mini_lm_similarity'].mean()\n",
    "    \n",
    "    # Save to new CSV file\n",
    "    output_file = 'IndianConstitution_filtered_results.csv'\n",
    "    df_filtered.to_csv(output_file, index=False)\n",
    "    print(f\"Filtered data saved to {output_file}\")\n",
    "    \n",
    "    # Print summary matrix\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Number of questions left: {len(df_filtered)}\")\n",
    "    print(f\"Number of questions removed: {removed_rows}\")\n",
    "    print(f\"Average BLEU: {avg_bleu:.4f}\")\n",
    "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "    print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
    "    print(f\"Average ROUGE-L: {avg_rougel:.4f}\")\n",
    "    print(f\"Average Embedding Similarity: {avg_embedding_sim:.4f}\")\n",
    "    print(f\"Average MiniLM Embedding Similarity: {avg_mini_lm_sim:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from IndianConstitution_incremental_results.csv...\n",
      "Initial number of rows: 487\n",
      "Phrases found in 159 rows:\n",
      "  'i am sorry': found in 31 rows\n",
      "  'i cannot': found in 34 rows\n",
      "  'i am unable': found in 59 rows\n",
      "  'agent stopped': found in 64 rows\n",
      "Number of rows removed: 159\n",
      "Number of rows remaining: 328\n",
      "Loading sentence transformer model...\n",
      "Computing embedding similarities...\n",
      "Filtered data saved to IndianConstitution_filtered_results.csv\n",
      "\n",
      "Summary:\n",
      "Number of questions left: 328\n",
      "Number of questions removed: 159\n",
      "Average BLEU: 0.2824\n",
      "Average ROUGE-1: 0.4735\n",
      "Average ROUGE-2: 0.3859\n",
      "Average ROUGE-L: 0.4531\n",
      "Average Embedding Similarity: 0.8951\n",
      "Average MiniLM Embedding Similarity: 0.6615\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def process_csv(input_file='IndianConstitution_incremental_results.csv'):\n",
    "    # Load the CSV file\n",
    "    print(f\"Loading data from {input_file}...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Count the initial number of rows\n",
    "    initial_row_count = len(df)\n",
    "    print(f\"Initial number of rows: {initial_row_count}\")\n",
    "    \n",
    "    # Define patterns to search for in generated answers - all lowercase\n",
    "    patterns = [\n",
    "        r'i am sorry', \n",
    "        r'i cannot', \n",
    "        r'i am unable', \n",
    "        r'agent stopped'\n",
    "    ]\n",
    "    \n",
    "    # Create a regex pattern\n",
    "    combined_pattern = '|'.join(patterns)\n",
    "    \n",
    "    # First convert generated_answer to lowercase, then check for patterns\n",
    "    df['lower_gen_answer'] = df['generated_answer'].str.lower()\n",
    "    mask = df['lower_gen_answer'].str.contains(combined_pattern, regex=True)\n",
    "    \n",
    "    # Log rows being removed for debugging\n",
    "    removed_rows_df = df[mask]\n",
    "    print(f\"Phrases found in {len(removed_rows_df)} rows:\")\n",
    "    for pattern in patterns:\n",
    "        pattern_mask = df['lower_gen_answer'].str.contains(pattern, regex=True)\n",
    "        count = pattern_mask.sum()\n",
    "        print(f\"  '{pattern}': found in {count} rows\")\n",
    "    \n",
    "    # Filter out rows containing the patterns\n",
    "    df_filtered = df[~mask]\n",
    "    \n",
    "    # Drop the temporary lowercase column\n",
    "    df_filtered = df_filtered.drop('lower_gen_answer', axis=1)\n",
    "    \n",
    "    # Count the number of rows removed\n",
    "    removed_rows = initial_row_count - len(df_filtered)\n",
    "    print(f\"Number of rows removed: {removed_rows}\")\n",
    "    print(f\"Number of rows remaining: {len(df_filtered)}\")\n",
    "    \n",
    "    # Load sentence transformer model\n",
    "    print(\"Loading sentence transformer model...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "    \n",
    "    # Compute embedding similarity\n",
    "    print(\"Computing embedding similarities...\")\n",
    "    embedding_similarities = []\n",
    "    \n",
    "    # Process in batches to avoid potential memory issues\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(df_filtered), batch_size):\n",
    "        batch = df_filtered.iloc[i:i+batch_size]\n",
    "        generated_embeddings = model.encode(batch['generated_answer'].tolist())\n",
    "        gold_embeddings = model.encode(batch['gold_answer'].tolist())\n",
    "        \n",
    "        for j in range(len(batch)):\n",
    "            gen_emb = generated_embeddings[j].reshape(1, -1)\n",
    "            gold_emb = gold_embeddings[j].reshape(1, -1)\n",
    "            similarity = cosine_similarity(gen_emb, gold_emb)[0][0]\n",
    "            embedding_similarities.append(similarity)\n",
    "    \n",
    "    # Add new column for embedding similarity\n",
    "    df_filtered['mini_lm_similarity'] = embedding_similarities\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_bleu = df_filtered['bleu'].mean()\n",
    "    avg_rouge1 = df_filtered['rouge-1'].mean()\n",
    "    avg_rouge2 = df_filtered['rouge-2'].mean()\n",
    "    avg_rougel = df_filtered['rouge-l'].mean()\n",
    "    avg_embedding_sim = df_filtered['embedding_similarity'].mean()\n",
    "    avg_mini_lm_sim = df_filtered['mini_lm_similarity'].mean()\n",
    "    \n",
    "    # Save to new CSV file\n",
    "    output_file = 'IndianConstitution_filtered_results.csv'\n",
    "    df_filtered.to_csv(output_file, index=False)\n",
    "    print(f\"Filtered data saved to {output_file}\")\n",
    "    \n",
    "    # Print summary matrix\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Number of questions left: {len(df_filtered)}\")\n",
    "    print(f\"Number of questions removed: {removed_rows}\")\n",
    "    print(f\"Average BLEU: {avg_bleu:.4f}\")\n",
    "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "    print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
    "    print(f\"Average ROUGE-L: {avg_rougel:.4f}\")\n",
    "    print(f\"Average Embedding Similarity: {avg_embedding_sim:.4f}\")\n",
    "    print(f\"Average MiniLM Embedding Similarity: {avg_mini_lm_sim:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mootcourtVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
