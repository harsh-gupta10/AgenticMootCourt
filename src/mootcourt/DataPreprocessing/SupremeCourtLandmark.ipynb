{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed. Data saved to supreme_court_judgments.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL of the Supreme Court landmark judgments page\n",
    "URL = \"https://www.sci.gov.in/landmark-judgment-summaries/\"\n",
    "\n",
    "# Send a request to fetch the webpage content\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Create an empty list to store judgment data\n",
    "judgments = []\n",
    "\n",
    "# Locate the judgment summary table\n",
    "table = soup.find(\"div\", class_=\"judgment_summary\")\n",
    "if table:\n",
    "    table = table.find(\"table\")\n",
    "    if table:\n",
    "        rows = table.find(\"tbody\").find_all(\"tr\")  # Find all table rows\n",
    "        for index, row in enumerate(rows, start=1):\n",
    "            columns = row.find_all(\"td\")\n",
    "            if len(columns) >= 5:  # Ensure there are enough columns\n",
    "                def get_text(col):\n",
    "                    if col.find(\"span\", class_=\"bt-content\"):\n",
    "                        return col.find(\"span\", class_=\"bt-content\").text.strip()\n",
    "                    return col.text.strip() if col.text.strip() else \"N/A\"\n",
    "                \n",
    "                serial_number = get_text(columns[0])\n",
    "                date_of_judgment = get_text(columns[1])\n",
    "                case_title = get_text(columns[2])\n",
    "                subject = get_text(columns[3])\n",
    "                judgment_summary = get_text(columns[4])\n",
    "                \n",
    "                # Append extracted data to the list\n",
    "                judgments.append([serial_number, date_of_judgment, case_title, subject, judgment_summary])\n",
    "\n",
    "# Convert the extracted data into a DataFrame\n",
    "columns = [\"Serial Number\", \"Date of Judgment\", \"Cause Title/Case No.\", \"Subject\", \"Judgment Summary\"]\n",
    "df = pd.DataFrame(judgments, columns=columns)\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv(\"supreme_court_judgments.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Scraping completed. Data saved to supreme_court_judgments.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for year 2000...\n",
      "Fetching data for year 2001...\n",
      "Fetching data for year 2002...\n",
      "Fetching data for year 2003...\n",
      "Fetching data for year 2004...\n",
      "Fetching data for year 2005...\n",
      "Fetching data for year 2006...\n",
      "Fetching data for year 2007...\n",
      "Fetching data for year 2008...\n",
      "Fetching data for year 2009...\n",
      "Fetching data for year 2010...\n",
      "Fetching data for year 2011...\n",
      "Fetching data for year 2012...\n",
      "Fetching data for year 2013...\n",
      "Fetching data for year 2014...\n",
      "Fetching data for year 2015...\n",
      "Fetching data for year 2016...\n",
      "Fetching data for year 2017...\n",
      "Fetching data for year 2018...\n",
      "Fetching data for year 2019...\n",
      "Fetching data for year 2020...\n",
      "Fetching data for year 2021...\n",
      "Fetching data for year 2022...\n",
      "Fetching data for year 2023...\n",
      "Fetching data for year 2024...\n",
      "Fetching data for year 2025...\n",
      "Scraping completed. Data saved to supreme_court_judgments_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re  # Import regex for cleaning unwanted text\n",
    "\n",
    "# Define the base URL of the Supreme Court landmark judgments page\n",
    "BASE_URL = \"https://www.sci.gov.in/landmark-judgment-summaries/\"\n",
    "\n",
    "# Create an empty list to store judgment data\n",
    "judgments = []\n",
    "\n",
    "# Function to clean unwanted text\n",
    "def clean_text(text):\n",
    "    if text:\n",
    "        text = text.strip()\n",
    "        # Remove \"Read More\", \"View Judgment\", and unnecessary text\n",
    "        text = re.sub(r\"(Read More|View Judgment)\", \"\", text, flags=re.IGNORECASE)\n",
    "        # Remove case summaries footnotes and references\n",
    "        text = re.sub(r\"© Supreme Court of India.*\", \"\", text, flags=re.DOTALL)\n",
    "        return text.strip()\n",
    "    return \"N/A\"\n",
    "\n",
    "# Loop through years from 2000 to 2025\n",
    "for year in range(2000, 2026):\n",
    "    print(f\"Fetching data for year {year}...\")\n",
    "    \n",
    "    # Send a request with the selected year\n",
    "    response = requests.post(BASE_URL, data={\"judgment_year\": str(year)})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Locate the judgment summary table\n",
    "    table = soup.find(\"div\", class_=\"judgment_summary\")\n",
    "    if table:\n",
    "        table = table.find(\"table\")\n",
    "        if table:\n",
    "            rows = table.find(\"tbody\").find_all(\"tr\")  # Find all table rows\n",
    "            for index, row in enumerate(rows, start=1):\n",
    "                columns = row.find_all(\"td\")\n",
    "                if len(columns) >= 5:  # Ensure there are enough columns\n",
    "                    \n",
    "                    # Extract values with cleaning\n",
    "                    serial_number = clean_text(columns[0].text if columns[0] else \"N/A\")\n",
    "                    date_of_judgment = clean_text(columns[1].text if columns[1] else \"N/A\")\n",
    "                    case_title = clean_text(columns[2].text if columns[2] else \"N/A\")\n",
    "                    subject = clean_text(columns[3].text if columns[3] else \"N/A\")\n",
    "                    judgment_summary = clean_text(columns[4].text if columns[4] else \"N/A\")\n",
    "                    \n",
    "                    # Append extracted and cleaned data to the list\n",
    "                    judgments.append([serial_number, date_of_judgment, case_title, subject, judgment_summary])\n",
    "\n",
    "# Convert the extracted data into a DataFrame\n",
    "columns = [\"Serial Number\", \"Date of Judgment\", \"Cause Title/Case No.\", \"Subject\", \"Judgment Summary\"]\n",
    "df = pd.DataFrame(judgments, columns=columns)\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv(\"supreme_court_judgments_cleaned.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Scraping completed. Data saved to supreme_court_judgments_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for year 2024...\n",
      "Fetching data for year 2025...\n",
      "Scraping completed. Data saved to supreme_court_judgments_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re  # Import regex for cleaning unwanted text\n",
    "\n",
    "# Define the base URL of the Supreme Court landmark judgments page\n",
    "BASE_URL = \"https://www.sci.gov.in/landmark-judgment-summaries/\"\n",
    "\n",
    "# Create an empty list to store judgment data\n",
    "judgments = []\n",
    "\n",
    "# Function to clean unwanted text\n",
    "def clean_text(text):\n",
    "    if text:\n",
    "        text = text.strip()\n",
    "        # Remove \"Read More\", \"View Judgment\", and unnecessary text\n",
    "        text = re.sub(r\"(Read More|View Judgment)\", \"\", text, flags=re.IGNORECASE)\n",
    "        # Remove case summaries footnotes and references\n",
    "        text = re.sub(r\"© Supreme Court of India.*\", \"\", text, flags=re.DOTALL)\n",
    "        return text.strip()\n",
    "    return \"N/A\"\n",
    "\n",
    "# Loop through years from 2000 to 2025\n",
    "for year in range(2024, 2026):\n",
    "    print(f\"Fetching data for year {year}...\")\n",
    "    \n",
    "    # Send a request with the selected year\n",
    "    response = requests.post(BASE_URL, data={\"judgment_year\": str(year)})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Locate the judgment summary table\n",
    "    table = soup.find(\"div\", class_=\"judgment_summary\")\n",
    "    if table:\n",
    "        table = table.find(\"table\")\n",
    "        if table:\n",
    "            rows = table.find(\"tbody\").find_all(\"tr\")  # Find all table rows\n",
    "            for index, row in enumerate(rows, start=1):\n",
    "                columns = row.find_all(\"td\")\n",
    "                if len(columns) >= 5:  # Ensure there are enough columns\n",
    "                    \n",
    "                    # Extract values with cleaning\n",
    "                    serial_number = clean_text(columns[0].text if columns[0] else \"N/A\")\n",
    "                    date_of_judgment = clean_text(columns[1].text if columns[1] else \"N/A\")\n",
    "                    case_title = clean_text(columns[2].text if columns[2] else \"N/A\")\n",
    "                    subject = clean_text(columns[3].text if columns[3] else \"N/A\")\n",
    "                    judgment_summary = clean_text(columns[4].text if columns[4] else \"N/A\")\n",
    "                    \n",
    "                    # Append extracted and cleaned data to the list\n",
    "                    judgments.append([serial_number, date_of_judgment, case_title, subject, judgment_summary])\n",
    "\n",
    "# Convert the extracted data into a DataFrame\n",
    "columns = [\"Serial Number\", \"Date of Judgment\", \"Cause Title/Case No.\", \"Subject\", \"Judgment Summary\"]\n",
    "df = pd.DataFrame(judgments, columns=columns)\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv(\"supreme_court_judgments_cleaned.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Scraping completed. Data saved to supreme_court_judgments_cleaned.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mootcourtVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
